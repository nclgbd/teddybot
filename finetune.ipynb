{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 1)) (6.29.4)\n",
      "Requirement already satisfied: jupyter in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 3)) (0.2.6)\n",
      "Requirement already satisfied: langchain-anthropic in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 4)) (0.1.17)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 5)) (0.2.6)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 6)) (0.0.3)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 7)) (0.1.13)\n",
      "Requirement already satisfied: nltk in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 8)) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 9)) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 11)) (1.0.1)\n",
      "Requirement already satisfied: rich in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 12)) (12.6.0)\n",
      "Requirement already satisfied: rich-cli in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 13)) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 15)) (3.7.5)\n",
      "Requirement already satisfied: textual in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 16)) (0.1.18)\n",
      "Requirement already satisfied: torch in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 17)) (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 18)) (0.18.1+cu121)\n",
      "Requirement already satisfied: transformers in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from -r requirements.txt (line 19)) (4.42.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (8.26.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (8.6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipykernel->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: notebook in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter->-r requirements.txt (line 2)) (7.2.1)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter->-r requirements.txt (line 2)) (5.5.2)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter->-r requirements.txt (line 2)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter->-r requirements.txt (line 2)) (7.16.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter->-r requirements.txt (line 2)) (8.1.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (0.2.10)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (0.1.82)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain->-r requirements.txt (line 3)) (8.4.2)\n",
      "Requirement already satisfied: anthropic<1,>=0.28.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-anthropic->-r requirements.txt (line 4)) (0.30.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-anthropic->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-community->-r requirements.txt (line 5)) (0.6.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-huggingface->-r requirements.txt (line 6)) (0.23.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-huggingface->-r requirements.txt (line 6)) (3.0.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-huggingface->-r requirements.txt (line 6)) (0.19.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-openai->-r requirements.txt (line 7)) (1.35.7)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-openai->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: click in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nltk->-r requirements.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nltk->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nltk->-r requirements.txt (line 8)) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nltk->-r requirements.txt (line 8)) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from pandas->-r requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from pandas->-r requirements.txt (line 10)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from pandas->-r requirements.txt (line 10)) (2024.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from rich->-r requirements.txt (line 12)) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from rich->-r requirements.txt (line 12)) (2.18.0)\n",
      "Requirement already satisfied: rich-rst<2.0.0,>=1.1.7 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from rich-cli->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 14)) (1.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 14)) (3.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (0.12.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (69.5.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (3.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from torch->-r requirements.txt (line 17)) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from torch->-r requirements.txt (line 17)) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from torch->-r requirements.txt (line 17)) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from torch->-r requirements.txt (line 17)) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from torch->-r requirements.txt (line 17)) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from torch->-r requirements.txt (line 17)) (2021.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from torchvision->-r requirements.txt (line 18)) (10.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from transformers->-r requirements.txt (line 19)) (0.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from anthropic<1,>=0.28.0->langchain-anthropic->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from anthropic<1,>=0.28.0->langchain-anthropic->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from anthropic<1,>=0.28.0->langchain-anthropic->-r requirements.txt (line 4)) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from anthropic<1,>=0.28.0->langchain-anthropic->-r requirements.txt (line 4)) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from anthropic<1,>=0.28.0->langchain-anthropic->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from click->nltk->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5)) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (3.0.47)\n",
      "Requirement already satisfied: stack-data in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 1)) (306)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain->-r requirements.txt (line 3)) (1.33)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 15)) (1.2.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirements.txt (line 3)) (3.10.5)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->-r requirements.txt (line 17)) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->-r requirements.txt (line 17)) (2021.13.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 3)) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 3)) (2024.6.2)\n",
      "Requirement already satisfied: docutils in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from rich-rst<2.0.0,>=1.1.7->rich-cli->-r requirements.txt (line 13)) (0.21.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->-r requirements.txt (line 15)) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->-r requirements.txt (line 15)) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 15)) (1.5.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 15)) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 15)) (7.0.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 2)) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 2)) (3.0.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 15)) (2.1.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 2)) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 2)) (2.27.2)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 2)) (4.2.3)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 2)) (0.2.4)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from qtconsole->jupyter->-r requirements.txt (line 2)) (2.4.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 17)) (1.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain-anthropic->-r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain-anthropic->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (0.20.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (2.0.13)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter->-r requirements.txt (line 2)) (2.2.5)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter->-r requirements.txt (line 2)) (2.15.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter->-r requirements.txt (line 2)) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter->-r requirements.txt (line 2)) (4.22.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 15)) (1.2.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter->-r requirements.txt (line 2)) (2.20.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: wrapt in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 15)) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 2)) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (21.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter->-r requirements.txt (line 2)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter->-r requirements.txt (line 2)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter->-r requirements.txt (line 2)) (0.18.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (20.11.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (24.6.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\nicol\\anaconda3\\envs\\llm-dev\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r requirements.txt (line 2)) (2.9.0.20240316)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from rich import inspect\n",
    "\n",
    "from utils import *\n",
    "\n",
    "console = setup_rich()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hehe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220127_210848.jpg\",\"prependIcon\":\"attachment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think I'm gonna stream playing im excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Time to impulse buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wait is pokemon diamond out?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [\"discord-4nkq7191ray\", \"discord-fv8dqxpzsem\"]\n",
    "data_dir = \".data/csv/\"\n",
    "filenames = [os.path.join(data_dir, f\"{f}.csv\") for f in filenames]\n",
    "train_data = pd.read_csv(filenames[1])\n",
    "test_data = pd.read_csv(filenames[0])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\Anaconda3\\envs\\llm-dev\\Lib\\site-packages\\transformers\\deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "loading file tokenizer.model from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\tokenizer.model\n",
      "loading file added_tokens.json from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\tokenizer_config.json\n",
      "loading file tokenizer.json from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\tokenizer.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file config.json from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\config.json\n",
      "Model config Phi3Config {\n",
      "  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\model.safetensors.index.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"pad_token_id\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba31f14b02e8464ea466d0876390f7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing Phi3ForCausalLM.\n",
      "\n",
      "All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-4k-instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at C:\\Users\\nicol\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\c1358f8a35e6d2af81890deffbbfa575b978c62f\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": [\n",
      "    32000,\n",
      "    32001,\n",
      "    32007\n",
      "  ],\n",
      "  \"pad_token_id\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">transformers.pipelines.text_generation.TextGenerationPipeline</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x0000026F512DD810</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mtransformers.pipelines.text_generation.TextGenerationPipeline\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x0000026F512DD810\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    trust_remote_code=True,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe(\"Can you explain LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭───────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">transformers.pipelines.text_generation.TextGenerationPipeline</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x0000026F512DD810</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&gt;</span><span style=\"color: #000080; text-decoration-color: #000080\"> ──────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-style: italic\">def </span><span style=\"font-weight: bold\">(</span>text_inputs, **kwargs<span style=\"font-weight: bold\">)</span>:                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Language generation pipeline using any `ModelWithLMHead`. This pipeline predicts the words that will follow a</span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">specified text prompt. When the underlying model is a conversational model, it can also accept one or more </span>     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">chats,</span>                                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">in which case the pipeline will operate in chat mode and will continue the </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">chat</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">s</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\"> by adding its </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">response</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">s</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Each chat takes the form of a list of dicts, where each dict contains </span><span style=\"color: #008000; text-decoration-color: #008000\">\"role\"</span><span style=\"color: #008080; text-decoration-color: #008080\"> and </span><span style=\"color: #008000; text-decoration-color: #008000\">\"content\"</span><span style=\"color: #008080; text-decoration-color: #008080\"> keys.</span>                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>       <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">binary_output</span> = <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>          <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">call_count</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">default_input_names</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>              <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">device</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">device</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cpu'</span><span style=\"font-weight: bold\">)</span>                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>   <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">feature_extractor</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>           <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">framework</span> = <span style=\"color: #008000; text-decoration-color: #008000\">'pt'</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>     <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">image_processor</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>           <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">modelcard</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">task</span> = <span style=\"color: #008000; text-decoration-color: #008000\">'text-generation'</span>                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>         <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">torch_dtype</span> = torch.float32                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>           <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">XL_PREFIX</span> = <span style=\"color: #008000; text-decoration-color: #008000\">\"\\n    In 1991, the remains of Russian Tsar Nicholas II and his family (except for Alexei</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">and Maria) are discovered. The\\n    voice of Nicholas's young son, Tsarevich Alexei </span>      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">Nikolaevich, narrates the remainder of the story. 1883 Western\\n    Siberia, a young </span>     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">Grigori Rasputin is asked by his father and a group of men to perform magic. Rasputin has</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">a vision\\n    and denounces one of the men as a horse thief. Although his father </span>         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">initially slaps him for making such an\\n    accusation, Rasputin watches as the man is </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">chased outside and beaten. Twenty years later, Rasputin sees a vision of\\n    the Virgin </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">Mary, prompting him to become a priest. Rasputin quickly becomes famous, with people, </span>    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">even a bishop,\\n    begging for his blessing. &lt;eod&gt; &lt;/s&gt; &lt;eos&gt;\\n    \"</span>                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34m<\u001b[0m\u001b[1;95mtransformers.pipelines.text_generation.TextGenerationPipeline\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x0000026F512DD810\u001b[0m\u001b[1;34m>\u001b[0m\u001b[34m \u001b[0m\u001b[34m─────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[3;96mdef \u001b[0m\u001b[1m(\u001b[0mtext_inputs, **kwargs\u001b[1m)\u001b[0m:                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mLanguage generation pipeline using any `ModelWithLMHead`. This pipeline predicts the words that will follow a\u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mspecified text prompt. When the underlying model is a conversational model, it can also accept one or more \u001b[0m     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mchats,\u001b[0m                                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36min which case the pipeline will operate in chat mode and will continue the \u001b[0m\u001b[1;35mchat\u001b[0m\u001b[1;36m(\u001b[0m\u001b[36ms\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m by adding its \u001b[0m\u001b[1;35mresponse\u001b[0m\u001b[1;36m(\u001b[0m\u001b[36ms\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m.\u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mEach chat takes the form of a list of dicts, where each dict contains \u001b[0m\u001b[32m\"role\"\u001b[0m\u001b[36m and \u001b[0m\u001b[32m\"content\"\u001b[0m\u001b[36m keys.\u001b[0m                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m       \u001b[3;33mbinary_output\u001b[0m = \u001b[3;91mFalse\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m          \u001b[3;33mcall_count\u001b[0m = \u001b[1;36m0\u001b[0m                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[3;33mdefault_input_names\u001b[0m = \u001b[3;35mNone\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m              \u001b[3;33mdevice\u001b[0m = \u001b[1;35mdevice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'cpu'\u001b[0m\u001b[1m)\u001b[0m                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m   \u001b[3;33mfeature_extractor\u001b[0m = \u001b[3;35mNone\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m           \u001b[3;33mframework\u001b[0m = \u001b[32m'pt'\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m     \u001b[3;33mimage_processor\u001b[0m = \u001b[3;35mNone\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m           \u001b[3;33mmodelcard\u001b[0m = \u001b[3;35mNone\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                \u001b[3;33mtask\u001b[0m = \u001b[32m'text-generation'\u001b[0m                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m         \u001b[3;33mtorch_dtype\u001b[0m = torch.float32                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m           \u001b[3;33mXL_PREFIX\u001b[0m = \u001b[32m\"\\n    In 1991, the remains of Russian Tsar Nicholas II and his family \u001b[0m\u001b[32m(\u001b[0m\u001b[32mexcept for Alexei\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                       \u001b[32mand Maria\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are discovered. The\\n    voice of Nicholas's young son, Tsarevich Alexei \u001b[0m      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                       \u001b[32mNikolaevich, narrates the remainder of the story. 1883 Western\\n    Siberia, a young \u001b[0m     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                       \u001b[32mGrigori Rasputin is asked by his father and a group of men to perform magic. Rasputin has\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                       \u001b[32ma vision\\n    and denounces one of the men as a horse thief. Although his father \u001b[0m         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                       \u001b[32minitially slaps him for making such an\\n    accusation, Rasputin watches as the man is \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                       \u001b[32mchased outside and beaten. Twenty years later, Rasputin sees a vision of\\n    the Virgin \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                       \u001b[32mMary, prompting him to become a priest. Rasputin quickly becomes famous, with people, \u001b[0m    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                       \u001b[32meven a bishop,\\n    begging for his blessing. \u001b[0m\u001b[32m<\u001b[0m\u001b[32meod\u001b[0m\u001b[32m>\u001b[0m\u001b[32m \u001b[0m\u001b[32m<\u001b[0m\u001b[32m/s\u001b[0m\u001b[32m>\u001b[0m\u001b[32m \u001b[0m\u001b[32m<\u001b[0m\u001b[32meos\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n    \"\u001b[0m                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inspect(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOODY TWO SHOES\n"
     ]
    }
   ],
   "source": [
    "sample = train_data.sample(1)[\"text\"].values[0]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
       "    features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51305</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    features: \u001b[1m[\u001b[0m\u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    num_rows: \u001b[1;36m51305\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">:WackyDebaters1:\n",
       "</pre>\n"
      ],
      "text/plain": [
       ":WackyDebaters1:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">584</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29956</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">547</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29891</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10251</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10412</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29896</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29901</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m584\u001b[0m, \u001b[1;36m29956\u001b[0m,   \u001b[1;36m547\u001b[0m, \u001b[1;36m29891\u001b[0m, \u001b[1;36m10251\u001b[0m, \u001b[1;36m10412\u001b[0m, \u001b[1;36m29896\u001b[0m, \u001b[1;36m29901\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = train_data.sample(1)[\"text\"].values[0]\n",
    "console.print(sample)\n",
    "input_ids = tokenizer.encode(sample, return_tensors=\"pt\")\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_data[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_encodings = tokenizer(texts[:5], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">dict_keys</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mdict_keys\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'input_ids'\u001b[0m, \u001b[32m'attention_mask'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e5be7e48a944e5be1da525ca26c161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbd5f26487c4baea55bd28d4f7d04cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4245 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3ForCausalLM</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3Model</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>embed_tokens<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32064</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">padding_idx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32000</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>embed_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>layers<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3DecoderLayer</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>self_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3Attention</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>o_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>qkv_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9216</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3MLP</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>gate_up_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16384</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>down_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>activation_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SiLU</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>input_layernorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3RMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">(</span>resid_attn_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>resid_mlp_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>post_attention_layernorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3RMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Phi3RMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>lm_head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32064</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35mPhi3ForCausalLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m: \u001b[1;35mPhi3Model\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0membed_tokens\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32064\u001b[0m, \u001b[1;36m3072\u001b[0m, \u001b[33mpadding_idx\u001b[0m=\u001b[1;36m32000\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0membed_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m31\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m32\u001b[0m x \u001b[1;35mPhi3DecoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mself_attn\u001b[1m)\u001b[0m: \u001b[1;35mPhi3Attention\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mo_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mqkv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m9216\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mPhi3RotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mPhi3MLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mgate_up_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m16384\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdown_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mactivation_fn\u001b[1m)\u001b[0m: \u001b[1;35mSiLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0minput_layernorm\u001b[1m)\u001b[0m: \u001b[1;35mPhi3RMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mresid_attn_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mresid_mlp_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpost_attention_layernorm\u001b[1m)\u001b[0m: \u001b[1;35mPhi3RMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mPhi3RMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlm_head\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m3072\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32064\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,291,456 || all params: 3,827,371,008 || trainable%: 0.1644\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=4,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\n",
    "        \"qkv_proj\",\n",
    "    ],\n",
    ")\n",
    "lora_model = get_peft_model(model, lora_config).to(device)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using auto half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: text. If text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 51,305\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 256\n",
      "  Total optimization steps = 600\n",
      "  Number of trainable parameters = 6,291,456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2959899000094f178cc265bd4c41872c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "output_dir = \".data/outputs/\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    eval_strategy=\"epoch\",\n",
    "    bf16=True,\n",
    "    gradient_accumulation_steps=256,\n",
    "    learning_rate=2e-5,\n",
    "    output_dir=output_dir,\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=True,\n",
    "    report_to=\"none\",\n",
    "    weight_decay=0.01,\n",
    "    auto_find_batch_size=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "console.print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
